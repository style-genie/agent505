import logging
logger = logging.getLogger(__name__)
import litellm
import json
import subprocess
import time
import os
import sys
from pathlib import Path
from dotenv import dotenv_values
import asyncio
from litellm import completion 
from pydantic import BaseModel, create_model
from uuid import uuid4
from src.agent.workflows.advisor1 import Advisor1
from example.workflows.tools import tools, fetch_elements_from_vector_db, get_json_element_by_id,init_user_database, read_user_data, write_user_data
default_provid_er="openrouter"
default_model="openrouter_scout"

uuid_4config = dotenv_values(Path(__file__).parent.parent.parent / ".env")
# todo
# for key, value in config.items():
#     os.environ[key] = value
# the reason i have this function here is that mcp functions can call this too

def send(manager,session_id_,msg,name,method_response="request"):
    """
    Send a message to the user via the manager.

    Parameters
    ----------
    manager : Manager
        The manager object responsible for handling message sending.
    session_id_ : str
        The session identifier for the current interaction.
    msg : str
        The message to send to the user.
    name : str
        The identifier for the sender of the message.
    method_response : str, optional
        The method response type. Defaults to 'request'.
    """
    body= {"message": msg,"uuid_":name,"method_response":method_response}
    print("\Sending MSG to user:---------------->\n")
    print(body)
    asyncio.create_task(manager.send_personal_message(session_id_,body)) 


def completion(mcp,msg,modelid_=default_model,args={}):
    """
    Generate a completion response using the specified model and message.

    Parameters
    ----------
    mcp : ModelContextProtocol
        The model context protocol instance used to interact with the models.
    msg : list
        The message(s) to send to the model for generating a response.
    modelid_ : str, optional
        The model identifier to use. Defaults to 'openrouter_scout'.
    args : dict, optional
        Additional arguments to customize the completion request.

    Returns
    -------
    dict
        The completion response generated by the model.
    """

    compl= mcp.completion(
                    messages=msg,
                    model=modelid_,
                    args=args
                )
    return compl
def compl_send(mcp,manager,session_id_,msg,id_,modelid_=default_model,method_response="request",args={}):
    """
    Sends a completion request to the specified model and forwards the response.

    Parameters
    ----------
    mcp : ModelContextProtocol
        The model context protocol instance used to interact with the models.
    manager : Manager
        The manager object responsible for handling message sending.
    session_id_ : str
        The session identifier for the current interaction.
    msg : list
        The message(s) to send to the model for generating a response.
    id_ : str
        The identifier of the sender or recipient of the message.
    modelid_ : str, optional
        The model identifier to use. Defaults to the global default model.
    method_response : str, optional
        The method response type. Defaults to 'request'.
    args : dict, optional
        Additional arguments to customize the completion request.

    Returns
    -------
    dict
        The completion response generated by the model.
    """

    compl= completion(mcp,msg,modelid_,args)
    print("\Sending completion to user:---------------->\n")
    print(compl)
    send(manager,session_id_,compl,id_,method_response)
    return compl  
  




class ModelContextProtocol:
    """
    ModelContextProtocol:
        The ModelContextProtocol class provides a protocol for interacting with models in a session.
        It manages the registration of models, providers, and hosts, and provides methods for sending messages to models and handling errors.
    
        Attributes:
            manager: The manager object that manages the session.
            session_id_: A unique identifier for the session.
            models: A dictionary of models available for use in the session.
            POSTGRES_USER: The PostgreSQL user for the session.
            POSTGRES_PASSWORD: The PostgreSQL password for the session.
            POSTGRES_DB: The PostgreSQL database for the session.
            PINECONE_API_KEY: The Pinecone API key for the session.
            INDEX_HOST: The index host for the session.
            NAMESPACE: The namespace for the session.
    
        Methods:
            __init__: Initializes the model context protocol with a manager and session ID.
            error: Handles errors by sending an error message to the client and printing the error.
            register_provider: Registers a provider with the model context protocol.
    """
    def error(self,error):
        if(self.manager):
            self.manager.send_personal_message(self.session_id_, {"message": f"Error received: {error}"})
            print(f"Error received: {error}")
        #raise ValueError(error)
    def __init__(self,manager,session_id_):
        self.models = {}
        self.session_id_ = session_id_
        self.manager = manager
        #   ----------> CHECKING IF POStGRES ENV IS SET <----------
        self.POSTGRES_USER=os.environ.get("POSTGRES_USER","stylegen")
        self.POSTGRES_PASSWORD=os.environ.get("POSTGRES_PASSWORD","stylegen")
        self.POSTGRES_DB=os.environ.get("POSTGRES_DB","main")
        if(self.POSTGRES_USER == ""):
            self.error("POSTGRES environment variables not set")
        #   ----------> CHECKING IF PINECONE_API_KEY IS SET <----------
        self.PINECONE_API_KEY = os.environ.get("PINECONE_API_KEY", "")
        if(self.PINECONE_API_KEY == ""):
            self.error("PINECONE_API_KEY environment variable not set")
        self.INDEX_HOST = os.environ.get("INDEX_HOST", "" )
        if self.INDEX_HOST == "":
            self.error("INDEX_HOST environment variable not set")
        self.NAMESPACE = os.environ.get("NAMESPACE", "__default__")
        #   ----------> CHECKING IF OPENROUTER_API_KEY IS SET <----------
        OPENROUTER_API_KEY=os.environ.get("OPENROUTER_API_KEY","")
        OPENROUTER_API_BASE=os.environ.get("OPENROUTER_API_BASE","https://openrouter.ai/api/v1")
        if OPENROUTER_API_KEY != "" and OPENROUTER_API_KEY is not None:
            self.register_provider("open_router",OPENROUTER_API_BASE,OPENROUTER_API_KEY,"openrouter")
        #   ----------> CHECKING IF OLLAMA_HOST IS SET <----------
        OLLAMA_HOST = os.environ.get("OLLAMA_HOST", "http://localhost:11434")
        OLLAMA_API_KEY = os.environ.get("OLLAMA_API_KEY", "")
        if OLLAMA_API_KEY != "":
            self.register_provider("ollama_local",OLLAMA_HOST,OLLAMA_API_KEY,"ollama")
        #   ----------> CHECKING IF OPENWEBUI_HOST IS SET <----------
        OPENWEBUI_HOST = os.environ.get("OPENWEBUI_HOST", "https://chat.kxsb.org/ollama")
        OPENWEBUI_API_KEY = os.environ.get("OPENWEBUI_API_KEY", "")
        if OPENWEBUI_API_KEY != "":
            self.register_provider("openwebui",OPENWEBUI_HOST,OPENWEBUI_API_KEY,"openwebui")
        #   ----------> CHECKING IF GEMINI_HOST IS SET <----------
        GEMINI_HOST = os.environ.get("GEMINI_HOST", "")
        GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "" )
        if GEMINI_API_KEY != "":
            self.register_provider("gemini",GEMINI_HOST,GEMINI_API_KEY,"gemini")
    
    
    # this function should get normalised for general use.
    # all those models should not get registered insid_e
    def register_provider(self, host_type, host_url, api_key,provid_er, arguments={}):
        """Registers a host after the server has started."""
        print(f"Registering {provid_er} host: {host_url}")
        # registering some models we need later for the agent workflows
        if host_type == "open_router":
            self.models["openrouter_gpt35"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/openai/gpt-3.5-turbo", "tools":False,**arguments} 
            self.models["openrouter_palm2"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/google/palm-2-chat-bison", "tools":False,**arguments}
            self.models["openrouter_llamaguard12b"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/meta-llama/llama-guard-4-12b", "tools":True,**arguments}
            self.models["openrouter_phi4_3"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/microsoft/phi-4-reasoning-plus", "tools":True,**arguments}
            self.models["openrouter_maverick"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/meta-llama/llama-4-maverick", "tools":True,**arguments}
            self.models["openrouter_scout"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/meta-llama/llama-4-scout", "tools":True,**arguments}
            self.models["openrouter_gemini_2.5_pro_p325"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/google/gemini-2.5-pro-preview-03-25", "tools":True,**arguments}
            self.models["openrouter_gemini_2.5_pro_e325"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/google/gemini-2.5-pro-exp-03-25", "tools":True,**arguments}
            self.models["openrouter_claude3.7"]={"api_key": api_key,"provid_er":"openrouter", "base_url": host_url, "model":"openrouter/anthropic/claude-3.7-sonnet", "tools":True,**arguments}
        elif host_type == "ollama_local":
            self.models["ollama_local"]={"api_key": api_key,"provid_er":"ollama", "base_url": host_url, "model":"ollama/gemma3:27b","tools":True, **arguments}
        elif host_type == "openwebui":
            self.models["openwebui"]={"api_key": api_key, "provid_er":"openwebui","base_url": host_url,"model":"ollama/gemma3:27b","tools":True, **arguments}
        elif host_type == "gemini":
            self.models["gemini"]={"api_key": api_key,"provid_er":"gemini", "base_url": host_url, "model": "gemini/gemini-1.5-pro","tools":True,**arguments}
        else:
            raise ValueError("Invalid_ host type. Must be 'ollama_local', 'gemini' or 'openwebui'.")
        try:
                new_host={f"{host_type}":{
                            "litellm_provid_er": provid_er,
                            "max_tokens": 8192,
                            "api_key": api_key,
                                          }}
                print(new_host)
                # we use base_url since api_base seems to be a deprecated argument
                host_type!= "open_router" and litellm.register_model(new_host)
                print(f"Registered host: {host_type}")
        except Exception as e:
            print(f"Failed to register host {provid_er}: {e}")
            sys.exit(1)
   
    def completion(self, messages, model=default_model,ignored_tools=[],args={}):
        """Tests parallel function calling."""
        print(self.models[model])
        modelid_=self.models[model]['model']
        provid_er=self.models[model]['provid_er']
        allow_tools=self.models[model]['tools']
        print("-----------------------------------------")
        print(f"model: {model}")
        
        print(f"baseurl: {self.models[model]['base_url']}")
        
        args={
            "model":modelid_,
            "messages":messages,
            "api_key":self.models[model]["api_key"],
            **args
        }
        if(provid_er=="open_router"):
            args["base_url"]=self.models[model]["base_url"] if "base_url" in self.models[model] else None
        if(allow_tools):
            args["tools"] = tools
            args["tool_choice"] = "auto"
        response = litellm.completion(**args,)
        response = dict(response)
        try:
            response_message = response["choices"][0].message.content
            json_response = response_message# json.loads(response_message)    
            print("------------------R-----------------------")
            print("\nLLM Response:\n")
            print(response_message)
            print("------------------R----------------------")
        except Exception as e:
            print("------------------E-----------------------")
            print(e)
            print("------------------E-----------------------")
            return {"error": "Unexpected response format from the model."}
        
        # Step 2: check if the model wanted to call a function
        tool_calls =  response_message.tool_calls if allow_tools  else False
        print("\nLength of tool calls", (tool_calls))
        if tool_calls:
            
            # Step 3: call the function
            # Note: the JSON response may not always be valid_; be sure to handle errors
            available_functions = {
                "get_json_element_by_id_": get_json_element_by_id,
                "fetch_elements_from_vector_db": fetch_elements_from_vector_db,
                "init_user_database":init_user_database, 
                "read_user_data":read_user_data, 
                "write_user_data":write_user_data
            }  
            messages.append(response_message)  # extend conversation with assistant's reply
            # Step 4: send the info for each function call and function response to the model
            for tool_call in tool_calls:
                function_name = tool_call.function.name
                function_to_call = available_functions[function_name]
                function_args = json.loads(tool_call.function.arguments)
                if function_name == "get_json_element_by_id_":
                    function_response = function_to_call(id_=function_args.get("id_"))
                else:
                    function_response = function_to_call(query=function_args.get("query"))
                messages.append(
                    {
                        "tool_call_id_": tool_call.id_,
                        "role": "tool",
                        "name": function_name,
                        "content": function_response,
                    }
                )  # extend conversation with function response
        # json_response["messages"] = messages
        
        # json_response["step"] = step+1
        return {"response":response_message,"messages":messages}

class BaseAgentModel(BaseModel):
    requiresUserResponse: int
    requiresToolResponse: int
    # hier weitere felder

class Agent():
    """
    Agent:
        The Agent class represents an autonomous entity that interacts with a session and a model to process messages and provide responses.
        It manages its own state and uses the model to generate responses to input messages.
        The agent can be configured to wait for specific responses from users or tools before taking action.
    
        Attributes:
            session: The session object that the agent is associated with.
            id_: A unique identifier for the agent.
            modelid_: The ID of the model used by the agent.
            working: A flag indicating whether the agent is currently working.
            waiting: A flag indicating whether the agent is waiting for a response.
    
        Methods:
            __init__: Initializes the agent with a session, name, model ID, and other parameters.
            waitTillReady: Waits until the agent is ready to process messages.
            checkIfready: Checks if the agent is ready to process messages.
            update: Updates the agent's state based on a received message.
            get_messages: Returns the agent's messages from the session's context registry.
            clear_messages: Clears the agent's messages from the session's context registry.
            checkCompletionStatus: Checks the completion status of a message and updates the agent's state if necessary.
            send: Sends a message to the session manager.
            compl_send: Sends a message to the model and updates the agent's state with the response.
            run: Runs the feedback loop by sending a message to the model with the agent's current state and receiving a response.
    """

    def  __init__(self, session,name, modelid_="openrouter_gpt35",args={}, pydantic_response=False, loop=False,system_isntructions=["you are a helpful assistant"]):
        self.session=session
        self.id_=(f"{name}_{str(uuid4())}")
        self.modelid_=modelid_
        self.working=True
        self.waiting=False
        self.advisor_instruction="advisor is currently happy with your work! keep on!"
        self.system_isntructions=system_isntructions
        self.args=args
        self.loop=loop
        
        if(pydantic_response):
            self.pydantic_response=pydantic_response
            self.recent_tool_response=False # we let the agent know that it has received a tool response
            self.recent_user_response=False # same goes for user response
            self.requiresUserResponse=False # also needs a response field in the pydantic response body
            self.requiesToolResponse=False  # same goes here
            AgentModel = create_model('AgentModel', foo=str, bar=(int, 123))
        
        session.contextRegistry.register_recipient("agent",self.id_)
    
    async def waitTillReady(self):
        while(self.checkIfready() == False):
            await asyncio.sleep(1)
            print(f"agent {self.id_} is not ready yet, sleeping")
        print(f"agent {self.id_} is ready")

        self.waiting=False
        self.run()
    def checkIfready(self):
        user=False
        tool=False
        working=self.working==False
        if(self.requiresUserResponse and self.recent_user_response):
            user=True
            self.requiresUserResponse=False
            self.recent_user_response=False
        if(self.requiesToolResponse and self.recent_tool_response):
            self.requiesToolResponse=False
            self.recent_tool_response=False
            tool=True
        if(user and tool and working):
            return True
        else:
            return False
        
    def update(self,msg):
        self.session.contextRegistry.update_agent(self.id_,msg)
        #   ----> check if need to wait for tool/user <----
        if(self.pydantic_response):
            self.checkCompletionStatus(msg)
            if(self.requiresUserResponse==True):
                if(msg.role=="user"):
                    self.recent_user_response=True
                else:
                    print("agent still waiting for user response")
                    self.working =False
            
            if(self.requiesToolResponse==True):
                if(msg.role=="tool"):
                    self.recent_tool_response=True
                else:
                    print("agent still waiting for tool response")
                    self.working =False
        #     ----> create sleeping task if needed <----
        if(self.checkIfready() == False):
            if(self.waiting == True):
                print("agent already busy")
                return
            else:
                self.waiting=True
                self.working=False
                asyncio.create_task(self.waitTillReady())
        elif(self.loop):
        #       ----> run feedback loop if ready <----
            self.run()
    def get_messages(self):
        return self.session.contextRegistry.agentMessages[self.id_]
    def clear_messages(self):
        self.session.contextRegistry.agentMessages[self.id_]=[]
    def checkCompletionStatus(self,msg):
        if(self.pydantic_response):
            if(msg.requiresUserResponse>0.5):
                self.requiresUserResponse=True
            if(msg.requiresToolResponse>0.5):
                self.requiesToolResponse=True
    def send(self,msg):
        method="response"
        send(self.session.manager,self.session.session_id_,msg,self.id_,method_response=method)
    def compl_send(self,msg,model,method_response,args):
        resp= compl_send(self.session.mcp,self.session.manager,self.session.session_id_,msg,model,method_response,args)
        self.session.contextRegistry.agentMessages[self.id_].append(resp)
        self.update(resp)
        return resp
    #       ----> run the feedback loop <----
    def run(self):
        """
        run:
            Runs the feedback loop by sending a message to the model with the agent's current state and receiving a response.
            The message includes the agent's last 8 messages, the current plan, user data, important notes, and any advisor instructions.
            The response is then processed and used to update the agent's state.
        """
        messages=[]
        last8= self.session.contextRegistry.agentMessages[self.id_][-8:]
        plan={"role":"plan","content": self.session.contextRegistry.plan}
        data={"role":"user_data","content": self.session.contextRegistry.data}
        important_notes={"role":"important_notes","content": self.session.contextRegistry.important_notes}
        advisor_instruction={"role":"advisor_instruction","content": self.session.advisor_instruction}
        # history={"role":"history","content": self.session.contextRegistry.history}
        messages.extend([plan,data,important_notes,advisor_instruction]) #history
        messages.extend(last8)
        self.compl_send(messages,self.modelid_,method_response="request",args=self.args)

class ContextRegistry():
    """
    ContextRegistry:
        The ContextRegistry class manages the context and state of a session, including messages, plans, user data, and other relevant information.
        It provides methods for updating and retrieving context information, as well as registering recipients (e.g. agents, crews) to receive messages.
    
        Attributes:
            session: The session object that the context registry is associated with.
            agentMessages: A dictionary of messages for each agent, keyed by agent ID.
            toolCalls: A list of tool calls.
            userMessages: A list of user messages.
            crewMessages: A dictionary of messages for each crew, keyed by crew ID.
            plan: The current plan.
            important_notes: Important notes.
            history: The session history.
            data: User data.
    
        Methods:
            __init__: Initializes the context registry with a session.
            register_recipient: Registers a recipient (e.g. agent, crew) to receive messages.
            update_agent: Updates the messages for a specific agent.
            update_crew: Updates the messages for a specific crew.
            update_tool: Updates the tool calls.
            update_user: Updates the user messages.
            get_crew: Returns the messages for a specific crew.
            get_user: Returns the user messages.
            get_tool: Returns the tool calls.
            get_agent: Returns the messages for a specific agent.
            update: Updates the context registry with new information.
    """
    def __init__(self,session):
        self.session=session
        self.agentMessages={}
        self.toolCalls=[]
        self.userMessages=[]
        self.crewMessages={}
        self.plan=""
        self.important_notes=""
        self.history=""
        self.data={}
    #    ----> register_recipient <----
    def register_recipient(self,_type,id_):
        if(_type=="agent"):
            self.agentMessages[id_]=[]
        elif(_type=="crew"):
            self.crewMessages[id_]=[]
        else:
            print("unknown recipient type")
    #       ----> setters <----
    def update_agent(self,id_,msg):
        self.agentMessages[id_].append(msg)
        self.session.agents[id_].update(msg)
    def update_crew(self,id_,msg):
        self.session.crews[id_].update(msg)
        self.crewMessages[id_].append(msg)
    def update_tool(self,id_,msg):
        self.toolCalls[id_].append(msg)
    def update_user(self,id_,msg):
        self.userMessages[id_].append(msg)
    #       ----> getters <----
    def get_crew(self,id_):
        return self.crewMessages[id_]
    def get_user(self,id_):
        return self.userMessages[id_]
    def get_tool(self,id_):
        return self.toolCalls[id_]
    def get_agent(self,id_):
        return self.agentMessages[id_]
    # ----> main update function <----
    def update(self,msg):
        method=msg.method
        role=msg.role
        content=msg.content
        if(method=="response"):
            # Agent or Crew is receiving a Message
            receipient=msg.receipient
            if(role=="user"):
                self.update_user(receipient,msg)
            elif(role=="tool"):
                self.update_tool(receipient,msg)
            if(receipient.split("_")[0]=="agent"):
                self.update_agent(receipient,msg)
            elif(receipient.split("_")[0]=="crew"):
                self.update_crew(receipient,msg)
            else:
                print("unknown receipient")
        # User is updating stuff, or something else happens that is not directly agent related                            
        elif(method=="updateUserSettings"):
            self.session.contextRegistry.user_data=msg
class MessageManager():
    """
    MessageManager:
        The MessageManager class manages the receipt and processing of messages in a session.
        It provides methods for listening for incoming messages and updating the session's context registry.
    
        Attributes:
            session: The session object that the message manager is associated with.
            task: The task object that runs the listener loop.
    
        Methods:
            __init__: Initializes the message manager with a session.
            listener: Listens for incoming messages and updates the session's context registry.
            init: Initializes the message manager and starts the listener loop.
            stop: Stops the listener loop and cancels the task.
    """
    async def listener(self):
        try:
            while True:
                    msg= await self.session.websocket.receive_text()
                    print(msg)
                    msg=json.loads(msg)
                    msg=msg.msg
                    self.session.contextRegistry.update(msg)
                    asyncio.sleep(10)
        except Exception as e:
            print(e)
            asyncio.sleep(1)
    def init(self,session):
        self.session=session
        self.task=asyncio.create_task(self.listener())
        
    def stop(self):
        self.task.cancel()
        self.task=None
        print("listener stopped")

@dataclass
class Task:
    id: str
    status: str
    progress: float
    children: List['Task']
    
# ----------> WEBSOCKET MANAGER <----------
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.tasks: Dict[str, Task] = {}

    async def connect(self, websocket: WebSocket, session_id: str):
        await websocket.accept()
        self.active_connections[session_id] = websocket

    def disconnect(self, session_id: str):
        if session_id in self.active_connections:
            del self.active_connections[session_id]

    async def send_personal_message(self, session_id: str, message: dict):
        if session_id in self.active_connections:
            await self.active_connections[session_id].send_json(message)
        else:
            raise WebSocketDisconnect(code=404, reason="Session not found")

    async def broadcast_task_update(self, task_id: str, status: str, progress: float):
        update = {"task_id": task_id, "status": status, "progress": progress}
        for ws in self.active_connections.values():
            await ws.send_json(update)

    async def receive_text(self, websocket: WebSocket):
        """Receives text from the WebSocket in a parallel async task and returns a promise."""
        try:
            data = await websocket.receive_text()
            return data
        except WebSocketDisconnect:
            return None
manager = ConnectionManager()

async def stream_task_progress(task_id: str):
    while True:
        task = manager.tasks.get(task_id)
        if task:
            yield json.dumps({
                "task_id": task.id,
                "status": task.status,
                "progress": task.progress
            })
        await asyncio.sleep(1)
class Session():
    """
    Session:
        The Session class represents a session, which is a container for a conversation or interaction between a user and a model.
        It manages the context and state of the conversation, including agents, crews, models, and messages.
    
        Attributes:
            manager: The manager object that manages the session.
            websocket: The websocket object that handles communication with the client.
            session_id_: A unique identifier for the session.
            models: A dictionary of models available for use in the session.
            max_recursion_depth: The maximum recursion depth for the session.
            agents: A dictionary of agents in the session, keyed by agent ID.
            crews: A dictionary of crews in the session, keyed by crew ID.
            contextRegistry: The context registry for the session.
            messageManager: The message manager for the session.
    
        Methods:
            __init__: Initializes the session with a manager, websocket, and session ID.
    """
    def __init__(self, manager,websocket,session_id_):
        self.mcp = ModelContextProtocol(manager,session_id_)
        manager = ConnectionManager()
        self.manager = manager


        self.websocket = websocket
        self.session_id_ = session_id_
        self.models = self.mcp.models
        self.agents={}
        self.crews={}
        self.contextRegistry=ContextRegistry()
        self.messageManager=MessageManager()        
        #flow = Advisor1(session=self,mcp=self.mcp,websocket=self.websocket,manager=self.manager,session_id_=self.session_id_)
        





# async def compl_send_await(websocket,mcp,manager,session_id_,msg,modelid_=default_model,method_response="request",args={}):
#     print(msg)
#     question= mcp.completion(
#                     messages=msg,
#                     model=modelid_,
#                     args=args
#                 )
#     name=str(uuid_4())
#     # tell the user you want something
#     print("\nAsking user for responce about:---------------->\n")
    
#     manager.respondMsgs[name]=None
#     question["method"]=method_response
#     asyncio.create_task(manager.send_personal_message(session_id_, {"message": question,"uuid_":name,"method_response":method_response})) 

#     print(f"question: {question} task: {name}")#question)
#     while True:
#         if(manager.respondMsgs[name] is not None):
#             response = manager.respondMsgs[name]
#             print("\nReceived User Response---------------->\n")
#             print(response)
#             break
#         else:
#             print(f"waiting for response of task: {name} - msg: {msg}")
#         time.sleep(10); 
#     return response  
  




# database_manager:
#   role: >
#     {topic} Senior Data Researcher
#   goal: >
#     Find the most relevant items using intelligent vector semantic search
#   backstory: >
#     You're a trained data analyst who accesses the vector database and finds the most relevant {topic} items.
#     You want to help the user finding suiting items and therefore you know how to find the right keywords. 
#     Known for your ability to find the most relevant
#     information and present it in a clear and concise manner.